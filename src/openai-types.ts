/**
 * Minimal OpenAI API TypeScript types
 * 
 * This file contains only the types actually used by this Cloudflare Worker.
 * Extracted from the official openai-node repository to ensure compatibility.
 * 
 * SOURCE REFERENCES:
 * - Repository: https://github.com/openai/openai-node
 * - Primary source: src/resources/chat/completions/completions.ts
 *   https://github.com/openai/openai-node/blob/main/src/resources/chat/completions/completions.ts
 * 
 * USED TYPES:
 * - ChatCompletionCreateParams: For incoming API requests
 * - ChatCompletion: For outgoing API responses  
 * - Related message and content types
 * 
 * @version Based on openai-node v4.x
 */

// ============================================================================
// Core Request/Response Types
// ============================================================================

/**
 * Parameters for creating a chat completion (simplified for this use case).
 * 
 * @source https://github.com/openai/openai-node/blob/main/src/resources/chat/completions/completions.ts#L1487
 */
export interface ChatCompletionCreateParams {
  /**
   * A list of messages comprising the conversation so far.
   */
  messages: Array<ChatCompletionMessageParam>;

  /**
   * ID of the model to use (optional for proxy usage).
   */
  model?: string;

  /**
   * What sampling temperature to use, between 0 and 2.
   */
  temperature?: number | null;

  /**
   * The maximum number of tokens that can be generated in the chat completion.
   */
  max_tokens?: number | null;

  /**
   * An alternative to sampling with temperature, called nucleus sampling.
   */
  top_p?: number | null;

  /**
   * If set, partial message deltas will be sent, like in ChatGPT.
   */
  stream?: boolean | null;

  /**
   * Up to 4 sequences where the API will stop generating further tokens.
   */
  stop?: string | Array<string> | null;

  // Allow additional properties for full OpenAI compatibility
  [key: string]: unknown;
}

/**
 * Represents a chat completion response returned by model.
 * 
 * @source https://github.com/openai/openai-node/blob/main/src/resources/chat/completions/completions.ts#L248
 */
export interface ChatCompletion {
  /**
   * A unique identifier for the chat completion.
   */
  id: string;

  /**
   * A list of chat completion choices.
   */
  choices: Array<ChatCompletion.Choice>;

  /**
   * The Unix timestamp (in seconds) of when the chat completion was created.
   */
  created: number;

  /**
   * The model used for the chat completion.
   */
  model: string;

  /**
   * The object type, which is always `chat.completion`.
   */
  object: 'chat.completion';

  /**
   * This fingerprint represents the backend configuration that the model runs with.
   */
  system_fingerprint?: string;

  /**
   * Usage statistics for the completion request.
   */
  usage?: CompletionUsage;
}

export namespace ChatCompletion {
  export interface Choice {
    /**
     * The reason the model stopped generating tokens.
     */
    finish_reason: 'stop' | 'length' | 'tool_calls' | 'content_filter' | 'function_call';

    /**
     * The index of the choice in the list of choices.
     */
    index: number;

    /**
     * Log probability information for the choice.
     */
    logprobs: null; // Simplified - not used in this implementation

    /**
     * A chat completion message generated by the model.
     */
    message: ChatCompletionMessage;
  }
}

// ============================================================================
// Message Types (Used in conversion functions)
// ============================================================================

/**
 * A chat completion message generated by the model.
 * 
 * @source https://github.com/openai/openai-node/blob/main/src/resources/chat/completions/completions.ts#L1000
 */
export interface ChatCompletionMessage {
  /**
   * The contents of the message.
   */
  content: string | null;

  /**
   * The refusal message generated by the model.
   */
  refusal: string | null;

  /**
   * The role of the author of this message.
   */
  role: 'assistant';
}

/**
 * Union type for all possible message parameters.
 */
export type ChatCompletionMessageParam =
  | ChatCompletionSystemMessageParam
  | ChatCompletionUserMessageParam
  | ChatCompletionAssistantMessageParam;

/**
 * System message parameter.
 */
export interface ChatCompletionSystemMessageParam {
  /**
   * The contents of the system message.
   */
  content: string;

  /**
   * The role of the messages author, in this case `system`.
   */
  role: 'system';

  /**
   * An optional name for the participant.
   */
  name?: string;
}

/**
 * User message parameter.
 */
export interface ChatCompletionUserMessageParam {
  /**
   * The contents of the user message.
   */
  content: string | Array<ChatCompletionContentPart>;

  /**
   * The role of the messages author, in this case `user`.
   */
  role: 'user';

  /**
   * An optional name for the participant.
   */
  name?: string;
}

/**
 * Assistant message parameter.
 */
export interface ChatCompletionAssistantMessageParam {
  /**
   * The contents of the assistant message.
   */
  content?: string | null;

  /**
   * The role of the messages author, in this case `assistant`.
   */
  role: 'assistant';

  /**
   * An optional name for the participant.
   */
  name?: string;
}

// ============================================================================
// Content Types (Used in message processing)
// ============================================================================

/**
 * Union type for different content parts in messages.
 * Simplified to only include text content (most common case).
 */
export type ChatCompletionContentPart = ChatCompletionContentPartText;

/**
 * Text content part.
 */
export interface ChatCompletionContentPartText {
  /**
   * The text content.
   */
  text: string;

  /**
   * The type of the content part.
   */
  type: 'text';
}

// ============================================================================
// Utility Types (Used in response)
// ============================================================================

/**
 * Usage statistics for the completion request.
 * 
 * @source https://github.com/openai/openai-node/blob/main/src/resources/completions.ts#L95
 */
export interface CompletionUsage {
  /**
   * Number of tokens in the generated completion.
   */
  completion_tokens: number;

  /**
   * Number of tokens in the prompt.
   */
  prompt_tokens: number;

  /**
   * Total number of tokens used in the request (prompt + completion).
   */
  total_tokens: number;
}

// ============================================================================
// MINIMAL TYPE SET DOCUMENTATION
// ============================================================================

/**
 * WHAT'S INCLUDED:
 * - ChatCompletionCreateParams: Input request format
 * - ChatCompletion: Output response format  
 * - Message parameter types: For processing incoming messages
 * - Content part types: For handling text content in messages
 * - CompletionUsage: For token usage reporting
 * 
 * WHAT'S EXCLUDED:
 * - Streaming types (ChatCompletionChunk)
 * - Tool/function calling types
 * - Image/audio content types  
 * - Advanced logprobs types
 * - Error types (using generic error handling)
 * - Deprecated function_call types
 * 
 * EXTENSION:
 * If you need additional types in the future, refer to the full openai-types.ts
 * or add specific types from:
 * https://github.com/openai/openai-node/blob/main/src/resources/chat/completions/completions.ts
 */